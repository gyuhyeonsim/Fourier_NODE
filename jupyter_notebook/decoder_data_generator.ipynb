{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process to make truncated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.chdir(\"/\".join(os.getcwd().split('/')[:-1]))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "import yaml\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "})\n",
    "\n",
    "with open('configs/rmsn_propensity.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "for k, v in config.items():\n",
    "    args.__setattr__(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mode': {'test': False},\n",
       " 'model': {'name': 'rmsn',\n",
       "  'phase': 3,\n",
       "  'cs_hidden_dim': 64,\n",
       "  'st_hidden_dim': 64,\n",
       "  'intervention_dim': 2,\n",
       "  'observation_dim': 2,\n",
       "  'latent_dim': 16,\n",
       "  'encoder_dim': 64,\n",
       "  'layer': 1,\n",
       "  'optimizer': 'ADAM',\n",
       "  'decoder_hidden_dim': 64,\n",
       "  'encoder_lr': 0.0001,\n",
       "  'encoder_epoch': 1000,\n",
       "  'decoder_lr': 0.0001,\n",
       "  'decoder_epoch': 1000},\n",
       " 'dataset': {'type': 'synthetic',\n",
       "  'path': './datasets/csv/synthetic_changed_itv_v_seed.csv',\n",
       "  'batch': 64,\n",
       "  'projection_horizon': 5,\n",
       "  'trunc_path': './rmsn_decoder_dataset/1224_test_3/',\n",
       "  'truncated_batch': 64,\n",
       "  'truncated_one_series': 47},\n",
       " 'gpus': '3',\n",
       " 'debug': False,\n",
       " 'exid': '1224_test_3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = args.dataset['path']\n",
    "dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>vel_x</th>\n",
       "      <th>vel_y</th>\n",
       "      <th>itv_x</th>\n",
       "      <th>itv_y</th>\n",
       "      <th>seed_x</th>\n",
       "      <th>seed_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.066326</td>\n",
       "      <td>-1.687203</td>\n",
       "      <td>-1.599490</td>\n",
       "      <td>4.218008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.082321</td>\n",
       "      <td>-1.645023</td>\n",
       "      <td>-1.623482</td>\n",
       "      <td>4.112558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.098556</td>\n",
       "      <td>-1.603898</td>\n",
       "      <td>-1.647834</td>\n",
       "      <td>4.009745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.115035</td>\n",
       "      <td>-1.563800</td>\n",
       "      <td>-1.672552</td>\n",
       "      <td>3.909501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.131760</td>\n",
       "      <td>-1.524705</td>\n",
       "      <td>-1.697640</td>\n",
       "      <td>3.811763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Time     pos_x     pos_y     vel_x     vel_y  itv_x  itv_y  seed_x  \\\n",
       "0  0.0  0.00 -1.066326 -1.687203 -1.599490  4.218008    0.0    0.0     0.0   \n",
       "1  0.0  0.01 -1.082321 -1.645023 -1.623482  4.112558    0.0    0.0     0.0   \n",
       "2  0.0  0.02 -1.098556 -1.603898 -1.647834  4.009745    0.0    0.0     0.0   \n",
       "3  0.0  0.03 -1.115035 -1.563800 -1.672552  3.909501    0.0    0.0     0.0   \n",
       "4  0.0  0.04 -1.131760 -1.524705 -1.697640  3.811763    0.0    0.0     0.0   \n",
       "\n",
       "   seed_y  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.dataset_uitls.get_dataloader import synthetic_regular_time_series\n",
    "from datasets.synthetic import *\n",
    "valid_data = Synthetic(path, idx=np.arange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "data_loader = DataLoader(dataset=valid_data, batch_size=1000,\n",
    "                                  shuffle=False,collate_fn=synthetic_regular_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = whole_data['obs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "truncate observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47000, 5, 2])\n",
      "torch.Size([47000, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "from copy import copy, deepcopy\n",
    "obs_list = []\n",
    "mask_list = []\n",
    "projection_horizon = 5\n",
    "idx_list = []\n",
    "\n",
    "for i in range(obs.size(0)):\n",
    "    for j in range(3, 50):\n",
    "        hidden_idx = torch.zeros(projection_horizon, 2) # hidden index -> {id, t}\n",
    "        hidden_idx[:,0]=i\n",
    "        hidden_idx[:,1]=j\n",
    "\n",
    "        idx_list.append(hidden_idx)\n",
    "        max_projection = min(projection_horizon, 50-j)\n",
    "        trun_obs = obs[i,j:j+max_projection]\n",
    "        mask = torch.zeros(projection_horizon, 2)\n",
    "        mask[:max_projection,:] = 1\n",
    "        \n",
    "        if max_projection!=5:\n",
    "            tmp = torch.zeros(mask.size())\n",
    "            tmp[:max_projection,:] = trun_obs\n",
    "            trun_obs = tmp\n",
    "            \n",
    "        obs_list.append(trun_obs)\n",
    "        mask_list.append(mask)\n",
    "        \n",
    "print(torch.stack(obs_list).size())\n",
    "print(torch.stack(mask_list).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_idx = torch.stack(idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "truncate intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "itv = whole_data['itv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "itv_list = []\n",
    "projection_horizon = 5\n",
    "\n",
    "for i in range(itv.size(0)):\n",
    "    for j in range(2, 49):\n",
    "        max_projection = min(projection_horizon, 49-j)\n",
    "        trun_itv = itv[i, j:j+max_projection]\n",
    "        mask = torch.zeros(projection_horizon, 3)  # considering intervention mask\n",
    "        mask[:max_projection,:] = 1\n",
    "\n",
    "        if max_projection!=5:\n",
    "            tmp = torch.zeros(mask.size())\n",
    "            tmp[:max_projection,:] = trun_itv\n",
    "            trun_itv = tmp\n",
    "        itv_list.append(trun_itv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47000, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(itv_list).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.stack(mask_list)\n",
    "b = b.reshape(-1)\n",
    "for k in b:\n",
    "    if k <0:\n",
    "        print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_dataset = torch.cat([hidden_idx, torch.stack(obs_list),torch.stack(mask_list), torch.stack(itv_list)], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47000, 5, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_dataset.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_dataset = truncated_dataset.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./rmsn_decoder_dataset/1224_test_3/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = './rmsn_decoder_dataset/'+args.exid+'/'\n",
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(base_path+'obs_mask_itv', truncated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Stabilized Weight File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed in Loading Stabilized Weights Nominator\n",
      "Succeed in Loading Stabilized Weights Denominator\n",
      "Succeed in Loading Censoring Nominator\n",
      "Succeed in Loading Censoring Denominator\n",
      "model: rmsn, number of params: 178186\n"
     ]
    }
   ],
   "source": [
    "from utils import Parser, get_dataloader, get_model, get_runner\n",
    "args.lr = 0.0001\n",
    "model, optim = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 1000, 1]) torch.Size([49, 1000, 1])\n"
     ]
    }
   ],
   "source": [
    "itv = whole_data['itv']\n",
    "epsilon=0.000001\n",
    "\n",
    "def gaussian_dist(obs, mean, var):\n",
    "    \"\"\"\n",
    "    :param obs:\n",
    "    :param mean:\n",
    "    :param var:\n",
    "    :return: p1 * p2\n",
    "    \"\"\"\n",
    "    return torch.exp((-0.5)*torch.pow((obs-mean)/var,2))/(var+epsilon)\n",
    "\n",
    "propensity = model\n",
    "obs = obs.float().permute(1,0,2)\n",
    "itv = itv.float()[:,:,:-1].permute(1,0,2)\n",
    "\n",
    "H = torch.cat([obs, itv], dim=2)\n",
    "censor_numerator = propensity.censor_numer.infer(obs) # update hidden\n",
    "censor_denominator = propensity.censor_denom.infer(H)\n",
    "censor_coeff = (censor_numerator/(censor_denominator+epsilon))\n",
    "\n",
    "# predict SW~\n",
    "_,_,_, sw_numerator = propensity.st_numer(obs)\n",
    "A_mean = torch.stack(sw_numerator[0])\n",
    "A_std = torch.stack(sw_numerator[1])\n",
    "sw_numerator = gaussian_dist(obs[1:,:,:], A_mean, A_std)\n",
    "\n",
    "H=torch.cat([obs[1:,:,:], itv[:itv.size(0)-1,:,:]],dim=2)\n",
    "_,_,_, sw_demoninator = propensity.st_denom(x=H, gt=obs)\n",
    "A_mean = torch.stack(sw_demoninator[0])\n",
    "A_std = torch.stack(sw_demoninator[1])\n",
    "sw_demoninator = gaussian_dist(obs[1:,:,:], A_mean, A_std)\n",
    "\n",
    "SW=1\n",
    "for i in range(sw_numerator.size(2)):\n",
    "    SW*=sw_numerator[:,:,i]/(sw_demoninator[:,:,i]+epsilon)\n",
    "SW = SW.unsqueeze(2)\n",
    "\n",
    "print(censor_coeff.size(), SW.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "CW = censor_coeff.permute(1,0,2)\n",
    "SW = SW.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a CW matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47000, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "CW_list = []\n",
    "mask_list = []\n",
    "projection_horizon = 6\n",
    "\n",
    "for i in range(CW.size(0)):\n",
    "    for j in range(0, 48):\n",
    "        max_projection = min(projection_horizon, 48-j)\n",
    "        trun_CW = CW[i,j:j+max_projection]\n",
    "        mask = torch.zeros(projection_horizon, 1)\n",
    "        mask[:max_projection,:] = 1\n",
    "        \n",
    "        if max_projection!=6:\n",
    "            if max_projection ==1:\n",
    "                continue\n",
    "            tmp = copy(mask)\n",
    "            tmp[:max_projection,:] = trun_CW\n",
    "            trun_CW = tmp\n",
    "            \n",
    "        CW_list.append(trun_CW)\n",
    "        mask_list.append(mask)\n",
    "print(torch.stack(CW_list).size())\n",
    "# print(torch.stack(mask_list).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_mat = torch.stack(CW_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_CW = torch.ones(CW_mat.size(0),CW_mat.size(1)-1, CW_mat.size(2))\n",
    "for i in range(1,6):\n",
    "    CW_mat[:,i,:] =CW_mat[:,i-1,:]*CW_mat[:,i,:]\n",
    "proc_CW = CW_mat[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47000, 5, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_CW.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a SW matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47000, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "SW_list = []\n",
    "mask_list = []\n",
    "projection_horizon = 6\n",
    "\n",
    "for i in range(SW.size(0)):\n",
    "    for j in range(0, 48):\n",
    "        max_projection = min(projection_horizon, 48-j)\n",
    "        trun_SW = SW[i,j:j+max_projection]\n",
    "        mask = torch.zeros(projection_horizon, 1)\n",
    "        mask[:max_projection,:] = 1\n",
    "        \n",
    "        if max_projection!=6:\n",
    "            if max_projection ==1:\n",
    "                continue\n",
    "            tmp = copy(mask)\n",
    "            tmp[:max_projection,:] = trun_SW\n",
    "            trun_SW = tmp\n",
    "            \n",
    "        SW_list.append(trun_SW)\n",
    "        mask_list.append(mask)\n",
    "        \n",
    "print(torch.stack(SW_list).size())\n",
    "# print(torch.stack(mask_list).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW_mat = torch.stack(SW_list)\n",
    "proc_SW = torch.ones(SW_mat.size(0),SW_mat.size(1)-1, SW_mat.size(2))\n",
    "for i in range(1,6):\n",
    "    SW_mat[:,i,:] =SW_mat[:,i-1,:]*SW_mat[:,i,:]\n",
    "proc_CW = CW_mat[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47000, 5, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_CW.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proc_SW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-50791b54142e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtruncated_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproc_SW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc_CW\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtruncated_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./rmsn_decoder_dataset/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'SW_CW'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proc_SW' is not defined"
     ]
    }
   ],
   "source": [
    "truncated_dataset = torch.cat([proc_SW, proc_CW], dim=2)\n",
    "truncated_dataset = truncated_dataset.detach().numpy()\n",
    "base_path = './rmsn_decoder_dataset/'+args.exid+'/'\n",
    "np.save(base_path+'SW_CW', truncated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Encoder Net] Encoder is initialized\n"
     ]
    }
   ],
   "source": [
    "from models.rmsn.encoder_net import EncoderNet\n",
    "input_dim = args.model['intervention_dim'] + \\\n",
    "            args.model['observation_dim']\n",
    "hidden_dim = args.model['encoder_dim']\n",
    "obs_dim = args.model['observation_dim']\n",
    "encoder = EncoderNet(input_dim, hidden_dim, obs_dim, propensity_net=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed in Loading Encoder\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('./save/{}/Encoder'.format(args.exid))['model_state_dict']\n",
    "encoder.load_state_dict(state_dict)\n",
    "print('Succeed in Loading Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _,hidden_v = encoder(torch.cat([obs.float(), itv[:,:,:-1].float()], dim=2).permute(1,0,2), gt=obs.float().permute(1,0,2), valid=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 1000, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './rmsn_decoder_dataset/1224_test_3/hidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2ae16a7a8edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './rmsn_decoder_dataset/1224_test_3/hidden'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path+='hidden'\n",
    "os.mkdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./rmsn_decoder_dataset/1224_test_3/hidden'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hidden_v.size(0)):\n",
    "    for j in range(hidden_v.size(1)):\n",
    "        v = hidden_v[i,j]\n",
    "        np.save(base_path+'/{}_{}'.format(j,i), v.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ode",
   "language": "python",
   "name": "ode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
